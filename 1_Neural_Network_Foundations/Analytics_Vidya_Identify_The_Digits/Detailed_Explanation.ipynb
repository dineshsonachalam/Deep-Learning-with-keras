{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['seed', 'imread', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from __future__ import print_function\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential    # Importing Sequential Model\n",
    "from keras.layers.core import Dense,Dropout, Activation  #  Importing  Dense Layers,Dropouts and Activation functions\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils  \n",
    "np.random.seed(1671) # for reproducibility -> Once you put the same seed you get same patterns of random numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Deep-Learning-with-keras\n",
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Deep-Learning-with-keras\\1_Neural_Network_Foundations\\Analytics_Vidya_Identify_The_Digits\n",
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Deep-Learning-with-keras\\1_Neural_Network_Foundations\\Analytics_Vidya_Identify_The_Digits\\sub\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath('../..')\n",
    "\n",
    "# check for existence\n",
    "print(os.path.exists(root_dir))\n",
    "print(root_dir)\n",
    "\n",
    "data_dir = os.path.join(root_dir,'1_Neural_Network_Foundations','Analytics_Vidya_Identify_The_Digits')\n",
    "print(os.path.exists(data_dir))\n",
    "print(data_dir)\n",
    "\n",
    "sub_dir = os.path.join(data_dir,'sub') \n",
    "print(os.path.exists(sub_dir))\n",
    "print(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir,'data','Train', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join('test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join('Sample_Submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    image_path = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " ..., \n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_x /= 255.0 \n",
    "train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    image_path = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "test_x /= 255.0\n",
    "test_x = test_x.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = keras.utils.np_utils.to_categorical(train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 50 # 30-> times the model is exposed to the training set.\n",
    "BATCH_SIZE = 300\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = Adam()\n",
    "N_HIDDEN = 128 # Neurons\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Final hidden layer  with 10 outputs\n",
    "# final stage is softmax\n",
    "model = Sequential() # Sequential Model.\n",
    "model.add(Dense(N_HIDDEN, input_shape=(784,))) # 1st Hidden Layer --> 128 neurons and input dimension ->784\n",
    "model.add(Activation('relu')) # Activation function for 1st Hidden Layer\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add(Dense(N_HIDDEN))  # 2nd Hidden Layer --> 128 neurons\n",
    "model.add(Activation('relu')) # Activation function for 2nd Hidden Layer\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "\n",
    "model.add(Dense(NB_CLASSES)) # Final layer with 10 neurons == > no of outputs\n",
    "model.add(Activation('softmax')) # Final layer activation will be 'softmax'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/50\n",
      "39200/39200 [==============================] - 2s 46us/step - loss: 0.7363 - acc: 0.7747 - val_loss: 0.2775 - val_acc: 0.9194\n",
      "Epoch 2/50\n",
      "39200/39200 [==============================] - 2s 38us/step - loss: 0.3051 - acc: 0.9091 - val_loss: 0.2005 - val_acc: 0.9401\n",
      "Epoch 3/50\n",
      "39200/39200 [==============================] - 2s 38us/step - loss: 0.2305 - acc: 0.9302 - val_loss: 0.1597 - val_acc: 0.9505\n",
      "Epoch 4/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.1906 - acc: 0.9436 - val_loss: 0.1351 - val_acc: 0.9586\n",
      "Epoch 5/50\n",
      "39200/39200 [==============================] - 2s 38us/step - loss: 0.1656 - acc: 0.9505 - val_loss: 0.1215 - val_acc: 0.9623\n",
      "Epoch 6/50\n",
      "39200/39200 [==============================] - 2s 38us/step - loss: 0.1475 - acc: 0.9554 - val_loss: 0.1127 - val_acc: 0.9644\n",
      "Epoch 7/50\n",
      "39200/39200 [==============================] - 2s 38us/step - loss: 0.1338 - acc: 0.9595 - val_loss: 0.1064 - val_acc: 0.9670\n",
      "Epoch 8/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.1195 - acc: 0.9634 - val_loss: 0.1053 - val_acc: 0.9672\n",
      "Epoch 9/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.1110 - acc: 0.9658 - val_loss: 0.0995 - val_acc: 0.9683\n",
      "Epoch 10/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0998 - acc: 0.9692 - val_loss: 0.0991 - val_acc: 0.9689\n",
      "Epoch 11/50\n",
      "39200/39200 [==============================] - 2s 38us/step - loss: 0.0952 - acc: 0.9709 - val_loss: 0.0912 - val_acc: 0.9704\n",
      "Epoch 12/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0890 - acc: 0.9716 - val_loss: 0.0918 - val_acc: 0.9711\n",
      "Epoch 13/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0830 - acc: 0.9739 - val_loss: 0.0878 - val_acc: 0.9730\n",
      "Epoch 14/50\n",
      "39200/39200 [==============================] - 2s 41us/step - loss: 0.0797 - acc: 0.9749 - val_loss: 0.0877 - val_acc: 0.9726\n",
      "Epoch 15/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0750 - acc: 0.9757 - val_loss: 0.0879 - val_acc: 0.9744\n",
      "Epoch 16/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0737 - acc: 0.9762 - val_loss: 0.0881 - val_acc: 0.9733\n",
      "Epoch 17/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0712 - acc: 0.9767 - val_loss: 0.0806 - val_acc: 0.9754\n",
      "Epoch 18/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0637 - acc: 0.9799 - val_loss: 0.0786 - val_acc: 0.9774\n",
      "Epoch 19/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0588 - acc: 0.9803 - val_loss: 0.0860 - val_acc: 0.9745\n",
      "Epoch 20/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0588 - acc: 0.9801 - val_loss: 0.0831 - val_acc: 0.9761\n",
      "Epoch 21/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0588 - acc: 0.9804 - val_loss: 0.0843 - val_acc: 0.9745\n",
      "Epoch 22/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0567 - acc: 0.9813 - val_loss: 0.0841 - val_acc: 0.9749\n",
      "Epoch 23/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0520 - acc: 0.9828 - val_loss: 0.0876 - val_acc: 0.9750\n",
      "Epoch 24/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0494 - acc: 0.9835 - val_loss: 0.0899 - val_acc: 0.9747\n",
      "Epoch 25/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0492 - acc: 0.9840 - val_loss: 0.0845 - val_acc: 0.9769\n",
      "Epoch 26/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0476 - acc: 0.9842 - val_loss: 0.0938 - val_acc: 0.9736\n",
      "Epoch 27/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0452 - acc: 0.9849 - val_loss: 0.0889 - val_acc: 0.9751\n",
      "Epoch 28/50\n",
      "39200/39200 [==============================] - 2s 41us/step - loss: 0.0443 - acc: 0.9856 - val_loss: 0.0958 - val_acc: 0.9733\n",
      "Epoch 29/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0416 - acc: 0.9860 - val_loss: 0.0974 - val_acc: 0.9745\n",
      "Epoch 30/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0428 - acc: 0.9857 - val_loss: 0.0961 - val_acc: 0.9749\n",
      "Epoch 31/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0394 - acc: 0.9866 - val_loss: 0.0865 - val_acc: 0.9760\n",
      "Epoch 32/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0409 - acc: 0.9864 - val_loss: 0.0873 - val_acc: 0.9770\n",
      "Epoch 33/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0380 - acc: 0.9879 - val_loss: 0.0885 - val_acc: 0.9768\n",
      "Epoch 34/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0908 - val_acc: 0.9764\n",
      "Epoch 35/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0394 - acc: 0.9866 - val_loss: 0.0879 - val_acc: 0.9764\n",
      "Epoch 36/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0373 - acc: 0.9875 - val_loss: 0.0914 - val_acc: 0.9752\n",
      "Epoch 37/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0369 - acc: 0.9868 - val_loss: 0.0916 - val_acc: 0.9778\n",
      "Epoch 38/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0353 - acc: 0.9883 - val_loss: 0.0936 - val_acc: 0.9750\n",
      "Epoch 39/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0370 - acc: 0.9873 - val_loss: 0.0872 - val_acc: 0.9773\n",
      "Epoch 40/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0366 - acc: 0.9876 - val_loss: 0.0908 - val_acc: 0.9771\n",
      "Epoch 41/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0306 - acc: 0.9900 - val_loss: 0.0927 - val_acc: 0.9758\n",
      "Epoch 42/50\n",
      "39200/39200 [==============================] - 2s 42us/step - loss: 0.0331 - acc: 0.9891 - val_loss: 0.0926 - val_acc: 0.9773\n",
      "Epoch 43/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0318 - acc: 0.9896 - val_loss: 0.0948 - val_acc: 0.9766\n",
      "Epoch 44/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0309 - acc: 0.9890 - val_loss: 0.0935 - val_acc: 0.9765\n",
      "Epoch 45/50\n",
      "39200/39200 [==============================] - 2s 42us/step - loss: 0.0330 - acc: 0.9889 - val_loss: 0.0964 - val_acc: 0.9754\n",
      "Epoch 46/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0316 - acc: 0.9891 - val_loss: 0.0971 - val_acc: 0.9761\n",
      "Epoch 47/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0299 - acc: 0.9901 - val_loss: 0.0924 - val_acc: 0.9774\n",
      "Epoch 48/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0284 - acc: 0.9903 - val_loss: 0.1036 - val_acc: 0.9738\n",
      "Epoch 49/50\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0270 - acc: 0.9909 - val_loss: 0.0993 - val_acc: 0.9770\n",
      "Epoch 50/50\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.0287 - acc: 0.9902 - val_loss: 0.1008 - val_acc: 0.9761\n"
     ]
    }
   ],
   "source": [
    "# Training a model in keras\n",
    "\n",
    "# Once the model is compiled it can be trained with the fit() function\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 1s 32us/step\n",
      "[4 0 4 ..., 6 6 2]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfgglfgglfgglfgglfgj1L2GPIg4nuFTeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16c1504bbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img_name = rng.choice(test.filename)\n",
    "filepath = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "test_index = int(img_name.split('.')[0]) - train.shape[0]\n",
    "\n",
    "print(\"Prediction is: \", pred[test_index])\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    filename  label\n",
      "0  49000.png      4\n",
      "1  49001.png      0\n",
      "2  49002.png      4\n",
      "3  49003.png      7\n",
      "4  49004.png      9\n"
     ]
    }
   ],
   "source": [
    "sample_submission.filename = test.filename; sample_submission.label = pred\n",
    "print(sample_submission.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(os.path.join(sub_dir, 'sub10.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
