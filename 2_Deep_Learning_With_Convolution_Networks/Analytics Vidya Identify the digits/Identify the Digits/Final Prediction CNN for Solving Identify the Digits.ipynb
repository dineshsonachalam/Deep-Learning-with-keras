{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from __future__ import print_function\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Deep-Learning-with-keras\\2_Deep_Learning_With_Convolution_Networks\n",
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Deep-Learning-with-keras\\2_Deep_Learning_With_Convolution_Networks\\Analytics Vidya Identify the digits\\Identify the Digits\n",
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Deep-Learning-with-keras\\2_Deep_Learning_With_Convolution_Networks\\Analytics Vidya Identify the digits\\Identify the Digits\\sub\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath('../..')\n",
    "\n",
    "# check for existence\n",
    "print(os.path.exists(root_dir))\n",
    "print(root_dir)\n",
    "\n",
    "\n",
    "\n",
    "data_dir = os.path.join(root_dir,'Analytics Vidya Identify the digits','Identify the Digits')\n",
    "print(os.path.exists(data_dir))\n",
    "print(data_dir)\n",
    "\n",
    "sub_dir = os.path.join(data_dir,'sub') \n",
    "print(os.path.exists(sub_dir))\n",
    "print(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir,'data','Train', 'train.csv')) # filename,labels\n",
    "train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 1, ..., 9, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        9\n",
       "2        1\n",
       "3        7\n",
       "4        3\n",
       "5        9\n",
       "6        4\n",
       "7        9\n",
       "8        3\n",
       "9        4\n",
       "10       2\n",
       "11       3\n",
       "12       6\n",
       "13       6\n",
       "14       0\n",
       "15       4\n",
       "16       8\n",
       "17       7\n",
       "18       9\n",
       "19       5\n",
       "20       3\n",
       "21       9\n",
       "22       1\n",
       "23       9\n",
       "24       6\n",
       "25       8\n",
       "26       9\n",
       "27       5\n",
       "28       7\n",
       "29       3\n",
       "        ..\n",
       "48970    7\n",
       "48971    5\n",
       "48972    0\n",
       "48973    1\n",
       "48974    4\n",
       "48975    1\n",
       "48976    7\n",
       "48977    5\n",
       "48978    6\n",
       "48979    5\n",
       "48980    6\n",
       "48981    3\n",
       "48982    5\n",
       "48983    5\n",
       "48984    9\n",
       "48985    2\n",
       "48986    9\n",
       "48987    0\n",
       "48988    0\n",
       "48989    7\n",
       "48990    0\n",
       "48991    1\n",
       "48992    1\n",
       "48993    6\n",
       "48994    9\n",
       "48995    2\n",
       "48996    4\n",
       "48997    9\n",
       "48998    3\n",
       "48999    0\n",
       "Name: label, Length: 49000, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename\n",
       "0  49000.png\n",
       "1  49001.png\n",
       "2  49002.png\n",
       "3  49003.png\n",
       "4  49004.png"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join('test.csv')) # filename\n",
    "test.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join('Sample_Submission.csv')) # sample submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef37170128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir,'data', 'Train', 'Images', 'train', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    image_path = os.path.join(data_dir,'data',  'Train', 'Images', 'train', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_x /= 255.0 \n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    image_path = os.path.join(data_dir,'data',  'Train', 'Images', 'test', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "test_x /= 255.0\n",
    "# test_x = test_x.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 1, 28, 28)\n",
      "(21000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x[:, np.newaxis, :, :]\n",
    "test_x = test_x[:,np.newaxis,:,:]\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering(\"th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "\n",
    "train_y = np_utils.to_categorical(train.label.values) #labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2\n",
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the ConvNet\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential() # Sequential model\n",
    "     \n",
    "        # CONV => RELU => POOL\n",
    "        \n",
    "        model.add(Conv2D(20, kernel_size=5, padding=\"same\",input_shape=input_shape))\n",
    "        # 20 ->  Convolutional kernel\n",
    "        # kernel_size = 5 --> Specify the value of spatial dimensions.\n",
    "        # padding ='same' --> We have an output same size as the input.\n",
    "        # input_shape --> input shape of the image\n",
    "        \n",
    "        model.add(Activation(\"relu\"))\n",
    "        # Activation --> Relu\n",
    "        model.add(Conv2D(50, kernel_size=5, border_mode=\"same\", activation='relu'))\n",
    "        \n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # pool_size = (2,2) --> Represents factors in which the image is vertically and horizontally downscaled.\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "       \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(50, kernel_size=5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(50, kernel_size=5, border_mode=\"same\",activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(50, kernel_size=5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(50, kernel_size=5,border_mode=\"same\", activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        \n",
    "        # Flatten => RELU layers   \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        # a softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, kernel_size=5, activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, kernel_size=5, padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, kernel_size=5, activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, kernel_size=5, padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, kernel_size=5, activation=\"relu\", padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/100\n",
      "39200/39200 [==============================] - 1340s 34ms/step - loss: 0.3637 - acc: 0.8786 - val_loss: 0.0765 - val_acc: 0.9766\n",
      "Epoch 2/100\n",
      "39200/39200 [==============================] - 1904s 49ms/step - loss: 0.0799 - acc: 0.9767 - val_loss: 0.0466 - val_acc: 0.9854\n",
      "Epoch 3/100\n",
      "39200/39200 [==============================] - 1908s 49ms/step - loss: 0.0620 - acc: 0.9817 - val_loss: 0.0458 - val_acc: 0.9862\n",
      "Epoch 4/100\n",
      "39200/39200 [==============================] - 2091s 53ms/step - loss: 0.0472 - acc: 0.9852 - val_loss: 0.0410 - val_acc: 0.9887\n",
      "Epoch 5/100\n",
      "39200/39200 [==============================] - 2021s 52ms/step - loss: 0.0405 - acc: 0.9882 - val_loss: 0.0344 - val_acc: 0.9905\n",
      "Epoch 6/100\n",
      "39200/39200 [==============================] - 2098s 54ms/step - loss: 0.0337 - acc: 0.9902 - val_loss: 0.0352 - val_acc: 0.9911\n",
      "Epoch 7/100\n",
      "39200/39200 [==============================] - 1924s 49ms/step - loss: 0.0284 - acc: 0.9914 - val_loss: 0.0310 - val_acc: 0.9923\n",
      "Epoch 8/100\n",
      "39200/39200 [==============================] - 2196s 56ms/step - loss: 0.0283 - acc: 0.9919 - val_loss: 0.0268 - val_acc: 0.9917\n",
      "Epoch 9/100\n",
      "39200/39200 [==============================] - 1919s 49ms/step - loss: 0.0259 - acc: 0.9924 - val_loss: 0.0299 - val_acc: 0.9921\n",
      "Epoch 10/100\n",
      "39200/39200 [==============================] - 1898s 48ms/step - loss: 0.0282 - acc: 0.9918 - val_loss: 0.0358 - val_acc: 0.9905\n",
      "Epoch 11/100\n",
      "39200/39200 [==============================] - 1836s 47ms/step - loss: 0.0240 - acc: 0.9931 - val_loss: 0.0325 - val_acc: 0.9907\n",
      "Epoch 12/100\n",
      "39200/39200 [==============================] - 1829s 47ms/step - loss: 0.0197 - acc: 0.9943 - val_loss: 0.0299 - val_acc: 0.9929\n",
      "Epoch 13/100\n",
      "39200/39200 [==============================] - 1826s 47ms/step - loss: 0.0211 - acc: 0.9937 - val_loss: 0.0282 - val_acc: 0.9932\n",
      "Epoch 14/100\n",
      "39200/39200 [==============================] - 1892s 48ms/step - loss: 0.0198 - acc: 0.9942 - val_loss: 0.0326 - val_acc: 0.9919\n",
      "Epoch 15/100\n",
      "39200/39200 [==============================] - 1843s 47ms/step - loss: 0.0223 - acc: 0.9935 - val_loss: 0.0381 - val_acc: 0.9911\n",
      "Epoch 16/100\n",
      "39200/39200 [==============================] - 1906s 49ms/step - loss: 0.0180 - acc: 0.9946 - val_loss: 0.0316 - val_acc: 0.9924\n",
      "Epoch 17/100\n",
      "39200/39200 [==============================] - 1904s 49ms/step - loss: 0.0189 - acc: 0.9944 - val_loss: 0.0305 - val_acc: 0.9929\n",
      "Epoch 18/100\n",
      "39200/39200 [==============================] - 1862s 47ms/step - loss: 0.0176 - acc: 0.9943 - val_loss: 0.0339 - val_acc: 0.9927\n",
      "Epoch 19/100\n",
      "39200/39200 [==============================] - 1826s 47ms/step - loss: 0.0176 - acc: 0.9949 - val_loss: 0.0313 - val_acc: 0.9935\n",
      "Epoch 20/100\n",
      "33792/39200 [========================>.....] - ETA: 4:00 - loss: 0.0168 - acc: 0.9952"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "sample_submission.filename = test.filename; sample_submission.label = pred\n",
    "sample_submission.to_csv(os.path.join(sub_dir, 'fianl_prediction.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
