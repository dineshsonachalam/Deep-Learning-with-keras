{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from __future__ import print_function\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Deep-Learning-with-keras\\2_Deep_Learning_With_Convolution_Networks\n",
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Deep-Learning-with-keras\\2_Deep_Learning_With_Convolution_Networks\\Analytics Vidya Identify the digits\\Identify the Digits\n",
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Deep-Learning-with-keras\\2_Deep_Learning_With_Convolution_Networks\\Analytics Vidya Identify the digits\\Identify the Digits\\sub\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath('../..')\n",
    "\n",
    "# check for existence\n",
    "print(os.path.exists(root_dir))\n",
    "print(root_dir)\n",
    "\n",
    "\n",
    "\n",
    "data_dir = os.path.join(root_dir,'Analytics Vidya Identify the digits','Identify the Digits')\n",
    "print(os.path.exists(data_dir))\n",
    "print(data_dir)\n",
    "\n",
    "sub_dir = os.path.join(data_dir,'sub') \n",
    "print(os.path.exists(sub_dir))\n",
    "print(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir,'data','Train', 'train.csv')) # filename,labels\n",
    "train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename\n",
       "0  49000.png\n",
       "1  49001.png\n",
       "2  49002.png\n",
       "3  49003.png\n",
       "4  49004.png"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join('test.csv')) # filename\n",
    "test.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join('Sample_Submission.csv')) # sample submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c35ccbbd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir,'data', 'Train', 'Images', 'train', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    image_path = os.path.join(data_dir,'data',  'Train', 'Images', 'train', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_x /= 255.0 \n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    image_path = os.path.join(data_dir,'data',  'Train', 'Images', 'test', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "test_x /= 255.0\n",
    "# test_x = test_x.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 1, 28, 28)\n",
      "(21000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x[:, np.newaxis, :, :]\n",
    "test_x = test_x[:,np.newaxis,:,:]\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering(\"th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "\n",
    "train_y = np_utils.to_categorical(train.label.values) #labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2\n",
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the ConvNet\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential() # Sequential model\n",
    "     \n",
    "        # CONV => RELU => POOL\n",
    "        \n",
    "        model.add(Conv2D(20, kernel_size=5, padding=\"same\",input_shape=input_shape))\n",
    "        # 20 ->  Convolutional kernel\n",
    "        # kernel_size = 5 --> Specify the value of spatial dimensions.\n",
    "        # padding ='same' --> We have an output same size as the input.\n",
    "        # input_shape --> input shape of the image\n",
    "        \n",
    "        model.add(Activation(\"relu\"))\n",
    "        # Activation --> Relu\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # pool_size = (2,2) --> Represents factors in which the image is vertically and horizontally downscaled.\n",
    "        \n",
    "       \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(50, kernel_size=5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Flatten => RELU layers   \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        \n",
    "        # a softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, kernel_size=5, padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/20\n",
      "39200/39200 [==============================] - 343s 9ms/step - loss: 0.2034 - acc: 0.9394 - val_loss: 0.0624 - val_acc: 0.9814\n",
      "Epoch 2/20\n",
      "39200/39200 [==============================] - 381s 10ms/step - loss: 0.0512 - acc: 0.9837 - val_loss: 0.0569 - val_acc: 0.9822\n",
      "Epoch 3/20\n",
      "39200/39200 [==============================] - 378s 10ms/step - loss: 0.0342 - acc: 0.9883 - val_loss: 0.0474 - val_acc: 0.9860\n",
      "Epoch 4/20\n",
      "39200/39200 [==============================] - 348s 9ms/step - loss: 0.0254 - acc: 0.9918 - val_loss: 0.0549 - val_acc: 0.9827\n",
      "Epoch 5/20\n",
      "39200/39200 [==============================] - 351s 9ms/step - loss: 0.0180 - acc: 0.9938 - val_loss: 0.0391 - val_acc: 0.9890\n",
      "Epoch 6/20\n",
      "39200/39200 [==============================] - 336s 9ms/step - loss: 0.0150 - acc: 0.9954 - val_loss: 0.0444 - val_acc: 0.9873\n",
      "Epoch 7/20\n",
      "39200/39200 [==============================] - 337s 9ms/step - loss: 0.0113 - acc: 0.9959 - val_loss: 0.0464 - val_acc: 0.9883\n",
      "Epoch 8/20\n",
      "39200/39200 [==============================] - 337s 9ms/step - loss: 0.0108 - acc: 0.9959 - val_loss: 0.0432 - val_acc: 0.9885\n",
      "Epoch 9/20\n",
      "39200/39200 [==============================] - 339s 9ms/step - loss: 0.0086 - acc: 0.9971 - val_loss: 0.0435 - val_acc: 0.9896\n",
      "Epoch 10/20\n",
      "39200/39200 [==============================] - 348s 9ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0487 - val_acc: 0.9883\n",
      "Epoch 11/20\n",
      "39200/39200 [==============================] - 338s 9ms/step - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0524 - val_acc: 0.9879\n",
      "Epoch 12/20\n",
      "39200/39200 [==============================] - 364s 9ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0475 - val_acc: 0.9897\n",
      "Epoch 13/20\n",
      "39200/39200 [==============================] - 402s 10ms/step - loss: 0.0056 - acc: 0.9980 - val_loss: 0.0493 - val_acc: 0.9877\n",
      "Epoch 14/20\n",
      "39200/39200 [==============================] - 750s 19ms/step - loss: 0.0079 - acc: 0.9979 - val_loss: 0.0413 - val_acc: 0.9902\n",
      "Epoch 15/20\n",
      "39200/39200 [==============================] - 340s 9ms/step - loss: 0.0047 - acc: 0.9981 - val_loss: 0.0449 - val_acc: 0.9907\n",
      "Epoch 16/20\n",
      "39200/39200 [==============================] - 349s 9ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 0.0425 - val_acc: 0.9914\n",
      "Epoch 17/20\n",
      "39200/39200 [==============================] - 238s 6ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0509 - val_acc: 0.9905\n",
      "Epoch 18/20\n",
      "39200/39200 [==============================] - 184s 5ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0607 - val_acc: 0.9877\n",
      "Epoch 19/20\n",
      "33408/39200 [========================>.....] - ETA: 23s - loss: 0.0071 - acc: 0.9975"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 49s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "sample_submission.filename = test.filename; sample_submission.label = pred\n",
    "sample_submission.to_csv(os.path.join(sub_dir, 'fianl_prediction.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
