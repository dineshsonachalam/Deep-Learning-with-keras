{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necessary libraries\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from __future__ import print_function\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential    # Importing Sequential Model\n",
    "from keras.layers.core import Dense,Dropout, Activation  #  Importing  Dense Layers,Dropouts and Activation functions\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils  \n",
    "np.random.seed(1671) # for reproducibility -> Once you put the same seed you get same patterns of random numbers.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train and Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\n",
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Analytics_Vidhya_ML_Projects\\Identify the Digits\n",
      "True\n",
      "C:\\Users\\Dinesh\\Desktop\\Analytics_Vidhya_ML_Projects\\Identify the Digits\\sub\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.abspath('../..')\n",
    "\n",
    "# check for existence\n",
    "print(os.path.exists(root_dir))\n",
    "print(root_dir)\n",
    "\n",
    "data_dir = os.path.join(root_dir,'Analytics_Vidhya_ML_Projects','Identify the Digits')\n",
    "print(os.path.exists(data_dir))\n",
    "print(data_dir)\n",
    "\n",
    "sub_dir = os.path.join(data_dir,'sub') \n",
    "print(os.path.exists(sub_dir))\n",
    "print(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir,'data','Train', 'train.csv')) # filename,labels\n",
    "train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename\n",
       "0  49000.png\n",
       "1  49001.png\n",
       "2  49002.png\n",
       "3  49003.png\n",
       "4  49004.png"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join('test.csv')) # filename\n",
    "test.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(os.path.join('Sample_Submission.csv')) # sample submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us see what our data looks like! We read our image and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eea05bde10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir,'data', 'Train', 'Images', 'train', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For easier data manipulation, letâ€™s store all our images as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    image_path = os.path.join(data_dir,'data',  'Train', 'Images', 'train', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "train_x /= 255.0 \n",
    "train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    image_path = os.path.join(data_dir,'data',  'Train', 'Images', 'test', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "test_x /= 255.0\n",
    "test_x = test_x.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot encoding of labels.\n",
    "A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
    "\n",
    "Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#  Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "\n",
    "train_y = keras.utils.np_utils.to_categorical(train.label.values) #labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images Shape: (49000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Images Shape:\",train_x.shape) # Training Images Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Labels dimension: (49000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Labels dimension:\",train_y.shape) # Training Labels Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Images Shape: (21000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Images Shape:\",test_x.shape) # Testing Images Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Network and Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 30 # 30-> times the model is exposed to the training set.\n",
    "BATCH_SIZE = 300\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = Adam()\n",
    "N_HIDDEN = 128 # Neurons\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Neural Network Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Final hidden layer  with 10 outputs\n",
    "# final stage is softmax\n",
    "model = Sequential() # Sequential Model.\n",
    "model.add(Dense(N_HIDDEN, input_shape=(784,))) # 1st Hidden Layer --> 128 neurons and input dimension ->784\n",
    "model.add(Activation('relu')) # Activation function for 1st Hidden Layer\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add(Dense(N_HIDDEN))  # 2nd Hidden Layer --> 128 neurons\n",
    "model.add(Activation('relu')) # Activation function for 2nd Hidden Layer\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "\n",
    "model.add(Dense(NB_CLASSES)) # Final layer with 10 neurons == > no of outputs\n",
    "model.add(Activation('softmax')) # Final layer activation will be 'softmax'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile network\n",
    "Before making network ready for training we have to make sure to add below things:\n",
    "\n",
    "1. A loss function: to measure how good the network is\n",
    "\n",
    "2. An optimizer: to update network as it sees more data and reduce loss value\n",
    "\n",
    "3. Metrics: to monitor performance of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling a model in keras\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model in keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/30\n",
      "39200/39200 [==============================] - 2s 51us/step - loss: 0.7364 - acc: 0.7744 - val_loss: 0.2774 - val_acc: 0.9199\n",
      "Epoch 2/30\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.3051 - acc: 0.9090 - val_loss: 0.2001 - val_acc: 0.9404\n",
      "Epoch 3/30\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.2307 - acc: 0.9303 - val_loss: 0.1596 - val_acc: 0.9501\n",
      "Epoch 4/30\n",
      "39200/39200 [==============================] - 2s 41us/step - loss: 0.1905 - acc: 0.9435 - val_loss: 0.1342 - val_acc: 0.9587\n",
      "Epoch 5/30\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.1650 - acc: 0.9501 - val_loss: 0.1218 - val_acc: 0.9620\n",
      "Epoch 6/30\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.1474 - acc: 0.9556 - val_loss: 0.1118 - val_acc: 0.9647\n",
      "Epoch 7/30\n",
      "39200/39200 [==============================] - 2s 42us/step - loss: 0.1328 - acc: 0.9595 - val_loss: 0.1073 - val_acc: 0.9667\n",
      "Epoch 8/30\n",
      "39200/39200 [==============================] - 2s 42us/step - loss: 0.1196 - acc: 0.9631 - val_loss: 0.1041 - val_acc: 0.9677\n",
      "Epoch 9/30\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.1109 - acc: 0.9656 - val_loss: 0.0993 - val_acc: 0.9692\n",
      "Epoch 10/30\n",
      "39200/39200 [==============================] - 2s 39us/step - loss: 0.1005 - acc: 0.9693 - val_loss: 0.1007 - val_acc: 0.9688\n",
      "Epoch 11/30\n",
      "39200/39200 [==============================] - 2s 44us/step - loss: 0.0942 - acc: 0.9716 - val_loss: 0.0901 - val_acc: 0.9717\n",
      "Epoch 12/30\n",
      "39200/39200 [==============================] - 2s 43us/step - loss: 0.0887 - acc: 0.9720 - val_loss: 0.0919 - val_acc: 0.9712\n",
      "Epoch 13/30\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0828 - acc: 0.9733 - val_loss: 0.0868 - val_acc: 0.9730\n",
      "Epoch 14/30\n",
      "39200/39200 [==============================] - 2s 41us/step - loss: 0.0783 - acc: 0.9753 - val_loss: 0.0884 - val_acc: 0.9737\n",
      "Epoch 15/30\n",
      "39200/39200 [==============================] - 2s 43us/step - loss: 0.0751 - acc: 0.9761 - val_loss: 0.0863 - val_acc: 0.9746\n",
      "Epoch 16/30\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0741 - acc: 0.9762 - val_loss: 0.0865 - val_acc: 0.9746\n",
      "Epoch 17/30\n",
      "39200/39200 [==============================] - 2s 43us/step - loss: 0.0706 - acc: 0.9770 - val_loss: 0.0806 - val_acc: 0.9756\n",
      "Epoch 18/30\n",
      "39200/39200 [==============================] - 2s 43us/step - loss: 0.0628 - acc: 0.9802 - val_loss: 0.0788 - val_acc: 0.9780\n",
      "Epoch 19/30\n",
      "39200/39200 [==============================] - 1s 38us/step - loss: 0.0584 - acc: 0.9806 - val_loss: 0.0850 - val_acc: 0.9746\n",
      "Epoch 20/30\n",
      "39200/39200 [==============================] - 1s 38us/step - loss: 0.0582 - acc: 0.9813 - val_loss: 0.0825 - val_acc: 0.9768\n",
      "Epoch 21/30\n",
      "39200/39200 [==============================] - 1s 37us/step - loss: 0.0578 - acc: 0.9804 - val_loss: 0.0848 - val_acc: 0.9744\n",
      "Epoch 22/30\n",
      "39200/39200 [==============================] - 2s 43us/step - loss: 0.0564 - acc: 0.9817 - val_loss: 0.0841 - val_acc: 0.9758\n",
      "Epoch 23/30\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0512 - acc: 0.9832 - val_loss: 0.0867 - val_acc: 0.9757\n",
      "Epoch 24/30\n",
      "39200/39200 [==============================] - 2s 41us/step - loss: 0.0502 - acc: 0.9839 - val_loss: 0.0932 - val_acc: 0.9735\n",
      "Epoch 25/30\n",
      "39200/39200 [==============================] - 2s 42us/step - loss: 0.0491 - acc: 0.9838 - val_loss: 0.0842 - val_acc: 0.9765\n",
      "Epoch 26/30\n",
      "39200/39200 [==============================] - 2s 41us/step - loss: 0.0465 - acc: 0.9844 - val_loss: 0.0928 - val_acc: 0.9754\n",
      "Epoch 27/30\n",
      "39200/39200 [==============================] - 2s 45us/step - loss: 0.0454 - acc: 0.9848 - val_loss: 0.0897 - val_acc: 0.9760\n",
      "Epoch 28/30\n",
      "39200/39200 [==============================] - 2s 44us/step - loss: 0.0434 - acc: 0.9854 - val_loss: 0.0942 - val_acc: 0.9742\n",
      "Epoch 29/30\n",
      "39200/39200 [==============================] - 2s 42us/step - loss: 0.0421 - acc: 0.9859 - val_loss: 0.0935 - val_acc: 0.9741\n",
      "Epoch 30/30\n",
      "39200/39200 [==============================] - 2s 40us/step - loss: 0.0424 - acc: 0.9859 - val_loss: 0.0942 - val_acc: 0.9759\n"
     ]
    }
   ],
   "source": [
    "# Training a model in keras\n",
    "\n",
    "# Once the model is compiled it can be trained with the fit() function\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 1s 33us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQyjxQyjxQyjxQ6i/AcRv8TjggPNvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ee9fdc9ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img_name = rng.choice(test.filename)\n",
    "filepath = os.path.join(data_dir,'data', 'Train', 'Images', 'test', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "test_index = int(img_name.split('.')[0]) - train.shape[0]\n",
    "\n",
    "print(\"Prediction is: \", pred[test_index])\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.filename = test.filename; sample_submission.label = pred\n",
    "sample_submission.to_csv(os.path.join(sub_dir, 'sub02.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
